{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "#importing mnist data from local .pkl file\n",
    "#encoding latin1 as due to version challenges. faced UnicodeDecodeError\n",
    "\n",
    "with gzip.open('mnist.pkl.gz','rb') as f:\n",
    "    (X_train, y_train), (X_test, y_test) = pickle.load(f,encoding='latin1')\n",
    "\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)    \n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "\n",
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train,number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test,number_of_classes)\n",
    "\n",
    "y_train.shape\n",
    "y_train[0]\n",
    "Y_train.shape\n",
    "Y_train[0]\n",
    "\n",
    "\n",
    "#till now, we have created the input X and output Y in desired format. Now lets build the CNN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each convolution layer correspond to three steps:\n",
    " 1. Convolution\n",
    " 2. Activation\n",
    " 3. Pooling\n",
    "\n",
    " Repeating 1,2,3 again will add more convolution layers..\n",
    "\n",
    "Input of CNN is WxHxD\n",
    "here it 28x28x1\n",
    "\n",
    "output will be based on \n",
    "num of filters, dimension of filter, padding, etc..\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape = (28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormaliation()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generting more images by rotating the existing ones..\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n",
    "\n",
    "# model.fit(X_train, Y_train, batch_size=128, nb_epoch=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n",
    "\n",
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "sub.to_csv('./output_cnn.csv', index=False)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
